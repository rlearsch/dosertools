{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://media.geeksforgeeks.org/wp-content/uploads/nba.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Team', 'Number', 'Position', 'Age', 'Height', 'Weight',\n",
       "       'College', 'Salary'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import file_handling.folder as folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = folder.parse_filename('0.8MDa-TPAM-1wtpct-0-FeCl','sampleinfo','MW-backbone-c-ratio-ion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample': '0.8MDa-TPAM-1wtpct-0-FeCl',\n",
       " 'MW': '0.8MDa',\n",
       " 'backbone': 'TPAM',\n",
       " 'c': '1wtpct',\n",
       " 'ratio': '0',\n",
       " 'ion': 'FeCl'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_summary_dataframe(df: pd.DataFrame, fitting_bounds: typing.Tuple[float, float] = [0.1, 0.045]) -> pd.DataFrame:\n",
    "    # add arguments for fh.folder.parse_filename\n",
    "    # \n",
    "    \"\"\"\n",
    "    Condenses a DOS run into an extensional relaxation time by fitting the EC region (t > tc) to a decaying exponential\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Contains R/R0, time, t - tc, strain rate, R(tc)/R0, etc for multiple runs and samples\n",
    "    fitting_bounds: list, optional\n",
    "        [start, end]\n",
    "        These are the R/R0 values we look for to set the bounds for the EC region fitting\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lambdaE_df : pd.DataFrame\n",
    "        dataframe containing lambdaE relaxation time for each run from the input df\n",
    "    \"\"\"\n",
    "    # Initalize parameters and empty list #\n",
    "    start = fitting_bounds[0]\n",
    "    end = fitting_bounds[1]\n",
    "    fitting_results_list = []\n",
    "    \n",
    "\n",
    "    samples = df[\"sample\"].unique()\n",
    "    for sample in samples:\n",
    "        # Grab sample info from \"sample\" field #\n",
    "        params = fh.folder.parse_filename(sample,\"sampleinfo\",sampleinfo_format,fname_split,sample_split)\n",
    "        # Select individual sample from df\n",
    "        sample_dataset = df[(df[\"sample\"] == sample)]\n",
    "        run_values = sample_dataset['run'].unique()\n",
    "        for run in run_values:\n",
    "            run_dataset = sample_dataset[(sample_dataset['run'] == run)]\n",
    "            run_dataset = run_dataset.reset_index(drop=True)\n",
    "            R_tc_R0 = run_dataset.loc[0, \"Rtc/R0\"]\n",
    "            fitting_results_temp =  [*params.values(), *find_EC_slope(run_dataset, start, end),run, R_tc_R0]\n",
    "            fitting_results_list.append(fitting_results_temp)\n",
    "    #### Clean up the dataframe column names ###\n",
    "    summary_df = annotate_summary_df(fitting_results_list)\n",
    "                                     ### Save the df as a csv later in integration ? ###\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{0:\"sample\", 1:\"-b\", 2:\"Intercept\", 3:\"R\",4:\"run\",5:\"Rtc/R0\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'key'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-b9898a6abd53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdf_header\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mdf_header\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'key'"
     ]
    }
   ],
   "source": [
    "# i need to reproduce the dictionary above\n",
    "df_header = {}\n",
    "for i in range(0, len(params)):\n",
    "    df_header[i] = params.key(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8MDa-TPAM-1wtpct-0-FeCl 0.8MDa TPAM 1wtpct 0 FeCl\n"
     ]
    }
   ],
   "source": [
    "print(*params.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample MW backbone c ratio ion\n"
     ]
    }
   ],
   "source": [
    "print(*params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = Path(csv).name\n",
    "params = fh.folder.parse_filename(fname,fname_format,sampleinfo_format,fname_split,sample_split)\n",
    "for key, value in params.items():\n",
    "    dataset[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(filename: str, fname_format: str, sampleinfo_format: str, fname_split: str =\"_\", sample_split: str ='-') -> dict:\n",
    "    \"\"\"\n",
    "    Parses filenames into a dictonary of parameters using supplied format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        the name of the folder\n",
    "        ex. \"20210929_6M-PEO_fps-25k_1\"\n",
    "    fname_format : str\n",
    "        the format of the filename with parameter names separated\n",
    "        by the deliminator specified by fname_split\n",
    "        ex. \"date_sampleinfo_fps_run\"\n",
    "    sampleinfo_format : str\n",
    "        the format of the sampleinfo section of the filename\n",
    "        separated by the deliminator specified by sample_split\n",
    "    fname_split : str, optional\n",
    "        the deliminator for splitting the filename (default is \"_\")\n",
    "    sample_split : str, optional\n",
    "        the deliminator for splitting the sampleinfo section\n",
    "        of the filename (default is \"-\")\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    parse_filename : dict\n",
    "        dictionary of parameters from filename\n",
    "    \"\"\"\n",
    "\n",
    "    # Split filename and format into components.\n",
    "    name_split = filename.split(fname_split)\n",
    "    tag_split = fname_format.split(fname_split)\n",
    "\n",
    "    param_dict = {} # initialize dictionary for outputting parameters from the filename\n",
    "\n",
    "    i = 0 # index in the folder name\n",
    "    for tag in tag_split:\n",
    "        value = name_split[i] # entry in the folder name corresponding to the tag from the fname_format\n",
    "\n",
    "        if \"fps\" in tag.lower():\n",
    "            if \"k\" in value: # check if fps is formated with k to represent 1000\n",
    "                fps = int(''.join(i for i in value if i.isdigit()))* 1000 # take numeric part of fps and multiply by 1000 if k was used, i.e. 25k becomes 25000\n",
    "            else:\n",
    "                fps = int(''.join(i for i in value if i.isdigit())) # take numeric part of fps only\n",
    "            param_dict[\"fps\"] = fps  # set entry in parameter dictionary\n",
    "        elif \"run\" in tag.lower(): # look for run number spec\n",
    "            param_dict[\"run\"] = int(''.join(i for i in value if i.isdigit())) # take numeric part of run only and set in parameter\n",
    "        elif \"sampleinfo\" in tag.lower():\n",
    "            param_dict[\"sample\"] = value # full sampleinfo in Sample column\n",
    "            sampleinfo_split = value.split(sample_split) # split sampleinfo using the sample_split deliminator\n",
    "            sample_tag_split = sampleinfo_format.split(sample_split) # split sampleinfo_format into sample tags using sample_split deliminator\n",
    "            j = 0 # index in the sampleinfo\n",
    "            for sample_tag in sample_tag_split:\n",
    "                sample_value = sampleinfo_split[j] # entry within sampleinfo coresponding to the sample_tag from the sampleinfo_format\n",
    "                param_dict[sample_tag] = sample_value # set entry in parameter dictionary\n",
    "                j = j + 1\n",
    "        else:\n",
    "            param_dict[tag] = value  # set entry in parameter dictionary\n",
    "        i = i + 1\n",
    "\n",
    "    return param_dict #output parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_summary_df(fitting_results_list: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Do we want to bring other columns with us like ion, polymer identity, etc? How to code that?\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fitting_results_list: list\n",
    "        generated by find_EC_slope\n",
    "    original_df : pd.DataFrame\n",
    "        Contains R/R0, time, t - tc, strain rate, R(tc)/R0, etc for multiple runs and samples\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lambdaE_df : pd.DataFrame\n",
    "        dataframe containing lambdaE relaxation time for each run from the input df\n",
    "    \"\"\"\n",
    "    lambdaE_df = pd.DataFrame(fitting_results_list)\n",
    "    lambdaE_df = lambdaE_df.rename(columns={0:\"sample\", 1:\"-b\", 2:\"Intercept\", 3:\"R\",4:\"run\",5:\"Rtc/R0\"})\n",
    "    lambdaE_df['Lambda E (s)'] = -1/(3*lambdaE_df['-b'])\n",
    "    lambdaE_df['Lambda E (ms)'] = lambdaE_df['Lambda E (s)']*1000\n",
    "    lambdaE_df['R^2'] = (lambdaE_df['R'])**2\n",
    "    lambdaE_df = lambdaE_df.drop([\"-b\",\"Intercept\",\"R\",\"Lambda E (s)\", ],axis=1)\n",
    "    return lambdaE_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
