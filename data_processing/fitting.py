import numpy as np
import pandas as pd
import os
import typing
import datetime

from scipy.optimize import curve_fit
from scipy.optimize import fsolve
from scipy import stats

import data_processing.array as dparray
import data_processing.csv as process
import file_handling.folder as folder
 
def find_EC_slope(run_dataset: pd.DataFrame, start: float, end: float) -> typing.Tuple[float, float, float]:
    """
    Finds the exponential decay of the EC region for a single dataset. Also returns the intercept and r value of the fit

    Parameters
    ----------
    run_dataset: pd.DataFrame
        dataset of a single DOS run containing at least R/R0, time,
    start: float
        value of R/R0 to start fitting the EC region from
    end: float
        value of R/R0 to end fitting the EC region with

    Returns
    -------
    slope, intercept, r_value: floats
        slope is the slope of the semilog-transformed version of the dataset. It corresponds to the decaying exponential in the linear-linear version of the data
    """
    start_index = dparray.closest_index_for_value(run_dataset, "R/R0", start)
    end_index = dparray.closest_index_for_value(run_dataset, "R/R0", end)
    dataset_EC = run_dataset[start_index:end_index]
    log_radius = np.log(dataset_EC['R/R0'])
    slope, intercept, r_value, p_value, std_err = stats.linregress(dataset_EC['time (s)'],log_radius)
    return slope, intercept, r_value

def annotate_summary_df(fitting_results_list: list, header_params: dict) -> pd.DataFrame:
    """
    Do we want to bring other columns with us like ion, polymer identity, etc? How to code that?

    Parameters
    ----------
    fitting_results_list: list
        generated by find_EC_slope
    header_params : dict
        Contains the information profiled in the samplename

    Returns
    -------
    lambdaE_df : pd.DataFrame
        dataframe containing lambdaE relaxation time for each run from the input df
    """
    lambdaE_df = pd.DataFrame(fitting_results_list)
    # Construct column headers for the summary dataframe #
    constant_fitting_header = ("-b","Intercept", "R","run","Rtc/R0")
    df_header = {}
    keys_list = header_params.keys()
    keys_list = list(keys_list)
    for i in range(0, len(header_params)):
        df_header[i] = keys_list[i]
    for i in range(len(header_params), (len(header_params) + len(constant_fitting_header))):
        df_header[i] = constant_fitting_header[i - len(header_params)]
        
    lambdaE_df = lambdaE_df.rename(columns=df_header)
    lambdaE_df['Lambda E (s)'] = -1/(3*lambdaE_df['-b'])
    lambdaE_df['Lambda E (ms)'] = lambdaE_df['Lambda E (s)']*1000
    lambdaE_df['R^2'] = (lambdaE_df['R'])**2
    lambdaE_df = lambdaE_df.drop(["-b","Intercept","R","Lambda E (s)", ],axis=1)
    return lambdaE_df

def make_summary_dataframe(df: pd.DataFrame, sampleinfo_format: str, fname_split: str ="_", sample_split: str ='-', fitting_bounds: typing.Tuple[float, float] = [0.1, 0.045]) -> pd.DataFrame:
#def make_summary_dataframe(df, fitting_bounds = [0.1, 0.045], sampleinfo_format, fname_split ="_", sample_split ='-'):

    """
    Condenses a DOS run into an extensional relaxation time by fitting the EC region (t > tc) to a decaying exponential

    Parameters
    ----------
    df : pd.DataFrame
        Contains R/R0, time, t - tc, strain rate, R(tc)/R0, etc for multiple runs and samples
    fitting_bounds: list, optional
        [start, end]
        These are the R/R0 values we look for to set the bounds for the EC region fitting
    sampleinfo_format : str
        the format of the sampleinfo section of the filename
        separated by the deliminator specified by sample_split
    fname_split : str, optional
        the deliminator for splitting the filename (default is "_")
    sample_split : str, optional
        the deliminator for splitting the sampleinfo section
        of the filename (default is "-")


    Returns
    -------
    summary_df : pd.DataFrame
        dataframe containing lambdaE (relaxation time) and R(t_c)/R_0 for each run from the input df, along with their sample info
    """
    # Initalize parameters and empty list #
    start = fitting_bounds[0]
    end = fitting_bounds[1]
    fitting_results_list = []
    

    samples = df["sample"].unique()
    for sample in samples:
        # Grab sample info from "sample" field #
        header_params = folder.parse_filename(sample,"sampleinfo",sampleinfo_format,fname_split,sample_split)
        # Select individual sample from df
        sample_dataset = df[(df["sample"] == sample)]
        run_values = sample_dataset['run'].unique()
        for run in run_values:
            run_dataset = sample_dataset[(sample_dataset['run'] == run)]
            run_dataset = run_dataset.reset_index(drop=True)
            R_tc_R0 = run_dataset.loc[0, "Rtc/R0"]
            fitting_results_temp =  [*header_params.values(), *find_EC_slope(run_dataset, start, end),run, R_tc_R0]
            fitting_results_list.append(fitting_results_temp)
    #### Clean up the dataframe column names ###
    summary_df = annotate_summary_df(fitting_results_list, header_params)
                                     ### Save the df as a csv later in integration ? ###
    return summary_df

def save_summary_df(summary_df: pd.DataFrame, save_location: typing.Union[str, bytes, os.PathLike], filename:str ='optional right now'):
    # right now, I'm not sure what information the computer will have about the files it's processing
    # because of this, I'm going to use the current date and time to name this summary csv
    # I anticipate we can come up with a better filename convention at a later time
    # thus, the filename arguemnt is present, but unused in the function
    
    date_and_time = datetime.datetime.now()
    #I don't want colons or periods in my filename string
    date_time_string = str(date_and_time.date()) + '_'+str(date_and_time.hour)+'-'+str(date_and_time.minute)+'-'+str(date_and_time.second)
    filename_string = date_time_string + '_DOS-summary.csv'
    full_save_path = os.path.join(save_location,filename_string)
    summary_df.to_csv(full_save_path)
    pass
